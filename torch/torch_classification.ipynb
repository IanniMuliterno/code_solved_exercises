{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steps \n",
    "\n",
    "* prepare data\n",
    "* design data/model (input,output)\n",
    "* construct loss and optmizer\n",
    "* training loop\n",
    "    - forwar pass: compute prediction and loss\n",
    "    - backward pass: gradients\n",
    "    - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib as mtl\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df_store = datasets.load_breast_cancer()\n",
    "\n",
    "#separate data and target\n",
    "X, y = df_store.data, df_store.target\n",
    "\n",
    "#split n_samples, n_features\n",
    "n_samples, n_features = X.shape[0], X.shape[1]\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3,random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let torchnization begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(X_train)\n",
    "scaled_test = scaler.transform(X_test)\n",
    "#torch.from_numpy (include astype)\n",
    "\n",
    "X_torch_train = torch.from_numpy(scaled_train.astype(np.float32))\n",
    "X_torch_test = torch.from_numpy(scaled_test.astype(np.float32))\n",
    "y_torch_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_torch_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's adjust the dimension of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_torch_train = y_torch_train.view(y_torch_train.shape[0],1)\n",
    "y_torch_test = y_torch_test.view(y_torch_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A big difference when we want to use torch\n",
    "#### transform your model in a module\n",
    "It brings more than the tidy advantages of modules, many pytorch utilities are design to work in modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model as a class\n",
    "class logisticreg(nn.Module):\n",
    "    def __init__(self, ini_features) -> None:\n",
    "        super(logisticreg, self).__init__()\n",
    "        self.linear = nn.Linear(ini_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred \n",
    "# call the model\n",
    "model = logisticreg(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define lr, loss function and optimizer\n",
    "epochs = range(100)\n",
    "lr = 0.05\n",
    "l = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0;  loss: 0.6271\n",
      "epoch: 10;  loss: 0.1059\n",
      "epoch: 20;  loss: 0.0796\n",
      "epoch: 30;  loss: 0.0713\n",
      "epoch: 40;  loss: 0.0677\n",
      "epoch: 50;  loss: 0.0655\n",
      "epoch: 60;  loss: 0.0641\n",
      "epoch: 70;  loss: 0.0630\n",
      "epoch: 80;  loss: 0.0620\n",
      "epoch: 90;  loss: 0.0610\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "''' \n",
    "1. foward or pred calculation\n",
    "2. loss \n",
    "3. backward ( or derivative)\n",
    "4. weights update/ gradient\n",
    "5. zero_grad before new iteration\n",
    "(optional) print verbose to every Nth epoch\n",
    "'''\n",
    "for i in epochs:\n",
    "\n",
    "    y_pred = model.forward(X_torch_train)\n",
    "    loss = l(y_pred,y_torch_train)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'epoch: {i};  loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9825\n"
     ]
    }
   ],
   "source": [
    "#plot accuracy\n",
    "with torch.no_grad():\n",
    "    test_pred = model(X_torch_test)\n",
    "    test_pred_class = test_pred.round()\n",
    "    # every prediction equals to actual 'y' is summed up and divided by 'y' length\n",
    "    acc = test_pred_class.eq(y_torch_test).sum() / float(y_torch_test.shape[0])\n",
    "    print(f'acc: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
