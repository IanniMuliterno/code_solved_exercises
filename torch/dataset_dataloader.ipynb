{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "sometimes we want to divide our training set in batches, because it's way too big for the computer to handle at once, dataset and dataloader take care of that for us. Before going into that, let's understand some core concepts\n",
    "\n",
    "1. epochs : complete cycle of foward and backward pass of the ENTIRE training set\n",
    "2. batch_size : size of sub sample that will be used as training set\n",
    "3. iteration : number of rounds, in one epoch, where one subsample was used\n",
    "\n",
    "e.g. 1.000.000 samples and batch_size of 5000 results in 200 iterations (1000000/5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class winedata(Dataset):\n",
    "    def __init__(self):\n",
    "        dt = \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
