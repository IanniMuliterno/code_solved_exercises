{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "sometimes we want to divide our training set in batches, because it's way too big for the computer to handle at once, dataset and dataloader take care of that for us. Before going into that, let's understand some core concepts\n",
    "\n",
    "1. epochs : complete cycle of foward and backward pass of the ENTIRE training set\n",
    "2. batch_size : size of sub sample that will be used as training set\n",
    "3. iteration : number of rounds, in one epoch, where one subsample was used\n",
    "\n",
    "e.g. 1.000.000 samples and batch_size of 5000 results in 200 iterations (1000000/5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import math\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class winedata(Dataset):\n",
    "    def __init__(self):\n",
    "        dt = np.loadtxt('wine.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
    "        self.x = dt[:,1:]\n",
    "        self.y = dt[:,[0]]\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index] ,self.y[index]\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.n_samples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = winedata()\n",
    "i = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking at row 10, predictors [1.41e+01 2.16e+00 2.30e+00 1.80e+01 1.05e+02 2.95e+00 3.32e+00 2.20e-01\n",
      " 2.38e+00 5.75e+00 1.25e+00 3.17e+00 1.51e+03], target [1.]\n"
     ]
    }
   ],
   "source": [
    "print(f'looking at row {i}, predictors {dt.__getitem__(i)[0]}, target {dt.__getitem__(i)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = 4\n",
    "dataloader = DataLoader(dataset=dt,batch_size=batch_s, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "n_samples = len(dt) \n",
    "iterations = n_samples/batch_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
