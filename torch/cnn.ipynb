{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device( 'cuda'  if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 2\n",
    "batch_size = 4\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='.\\data', transform=transform,\n",
    "                                             train=True, download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.\\data', transform=transform,\n",
    "                                            train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter  = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(3,6,5)\n",
    "        self.pooling = nn.MaxPool2d(2,2)\n",
    "        self.cnn2 = nn.Conv2d(6,16,5)\n",
    "\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "         # -> n, 3, 32, 32\n",
    "         def __init__(self):\n",
    "             super(ConvNet, self).__init__()\n",
    "             x = self.pooling(F.relu(self.cnn1(x)))     # -> n, 6, 14, 14\n",
    "             x = self.pooling(F.relu(self.cnn2(x)))# -> n, 16, 5, 5\n",
    "             x =x.view(-1, 16*5*5) # -> n, 400\n",
    "             x = self.fc1(x) # -> n, 120\n",
    "             x = self.fc2(x) # -> n, 84\n",
    "             x = self.fc3(x) # -> n, 10\n",
    "             return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2000/12500], Loss: 2.3117\n",
      "Epoch [1/5], Step [4000/12500], Loss: 2.2796\n",
      "Epoch [1/5], Step [6000/12500], Loss: 2.3105\n",
      "Epoch [1/5], Step [8000/12500], Loss: 2.3061\n",
      "Epoch [1/5], Step [10000/12500], Loss: 2.3034\n",
      "Epoch [1/5], Step [12000/12500], Loss: 2.1105\n",
      "Epoch [2/5], Step [2000/12500], Loss: 1.8461\n",
      "Epoch [2/5], Step [4000/12500], Loss: 1.8025\n",
      "Epoch [2/5], Step [6000/12500], Loss: 1.4768\n",
      "Epoch [2/5], Step [8000/12500], Loss: 2.1638\n",
      "Epoch [2/5], Step [10000/12500], Loss: 1.9670\n",
      "Epoch [2/5], Step [12000/12500], Loss: 1.6845\n",
      "Epoch [3/5], Step [2000/12500], Loss: 1.7840\n",
      "Epoch [3/5], Step [4000/12500], Loss: 2.3478\n",
      "Epoch [3/5], Step [6000/12500], Loss: 1.3317\n",
      "Epoch [3/5], Step [8000/12500], Loss: 1.2677\n",
      "Epoch [3/5], Step [10000/12500], Loss: 1.1060\n",
      "Epoch [3/5], Step [12000/12500], Loss: 0.9136\n",
      "Epoch [4/5], Step [2000/12500], Loss: 1.2148\n",
      "Epoch [4/5], Step [4000/12500], Loss: 1.0387\n",
      "Epoch [4/5], Step [6000/12500], Loss: 1.3851\n",
      "Epoch [4/5], Step [8000/12500], Loss: 1.2583\n",
      "Epoch [4/5], Step [10000/12500], Loss: 1.5884\n",
      "Epoch [4/5], Step [12000/12500], Loss: 1.7141\n",
      "Epoch [5/5], Step [2000/12500], Loss: 2.0525\n",
      "Epoch [5/5], Step [4000/12500], Loss: 0.9734\n",
      "Epoch [5/5], Step [6000/12500], Loss: 1.6112\n",
      "Epoch [5/5], Step [8000/12500], Loss: 1.1660\n",
      "Epoch [5/5], Step [10000/12500], Loss: 1.1760\n",
      "Epoch [5/5], Step [12000/12500], Loss: 1.3780\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network: 49.37 %\n",
      "Accuracy of plane: 60.4 %\n",
      "Accuracy of car: 77.1 %\n",
      "Accuracy of bird: 34.5 %\n",
      "Accuracy of cat: 22.2 %\n",
      "Accuracy of deer: 30.4 %\n",
      "Accuracy of dog: 37.8 %\n",
      "Accuracy of frog: 66.7 %\n",
      "Accuracy of horse: 62.1 %\n",
      "Accuracy of ship: 56.0 %\n",
      "Accuracy of truck: 46.5 %\n"
     ]
    }
   ],
   "source": [
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
